<!-- 
Combined Study Guide
Generated by LectureQ
Date: 2025-08-08 03:02:44
Week/Module: Week 1 Introduction
Files Combined: 6
Content Type: Mixed
-->

# Week 1 Introduction - Complete Study Guide

> **Auto-generated combined study guide**  
> Generated from 6 individual notes files  
> Date: August 08, 2025

## ðŸ“š Table of Contents

1. [Title: COMP SCI 3307/7307 - Secure Programming Week 1 Notes](#title-comp-sci-3307/7307---secure-programming-week-1-notes)
2. [Week 1: Attack Trees - Comprehensive Lecture Notes](#week-1-attack-trees---comprehensive-lecture-notes)
3. [Chapter 27: Secure Systems Development - Safety Critical Systems (Week 1 Introduction)](#chapter-27-secure-systems-development---safety-critical-systems-(week-1-introduction))
4. [Chapter 2: Who Is The Opponent?](#chapter-2-who-is-the-opponent?)
5. [Chapter 3: Passwords - Comprehensive Study Notes](#chapter-3-passwords---comprehensive-study-notes)
6. [Week 1: The Key To Capability Alignment](#week-1-the-key-to-capability-alignment)


---

# Title: COMP SCI 3307/7307 - Secure Programming Week 1 Notes

<think>
I need to create comprehensive, well-structured markdown notes from the lecture slides and transcript for COMP SCI 3307/7307 - Secure Programming, Week 1.

Let me analyze the content and organize it into a logical structure for my notes.

First, I'll identify the main sections from the slides and transcript:

1. Course introduction and acknowledgments
2. Why secure programming is needed (with examples)
3. Course overview and structure
4. Course prerequisites and expectations
5. Course assessment details
6. RangeForce platform details
7. Group project details (Advanced Secure Protocol Design, Implementation and Review)
8. Late submission and academic integrity policies

Now I'll organize these into a logical flow for my notes.

I'll start with a title and overview, then go through each section in detail, synthesizing both the slides and transcript.

Let me create the notes:

# Date: [Current Date]

### Overview
This document contains comprehensive notes for Week 1 of COMP SCI 3307/7307 - Secure Programming, covering course introduction, rationale for secure programming, course structure, assessment details, and key concepts.

Now I'll create the detailed notes section by section.

First, I'll cover the acknowledgments and course introduction from Slide 2 and the transcript.

Then I'll cover the "Why Secure Programming?" section with examples from Slides 4, 9, 10, 11, and the transcript.

Next, I'll cover the course overview, prerequisites, and expectations from Slides 14-15.

Then I'll cover the assessment details from Slides 18-19, 20-34, and the transcript.

Then I'll cover the RangeForce platform details from Slides 19-34.

Then I'll cover the group project details from Slides 35-37 and the transcript.

Finally, I'll cover the late submission policy, academic integrity, and key takeaways.

Let me now create the detailed notes in markdown format.
</think>

# COMP SCI 3307/7307 - Secure Programming: Week 1 Comprehensive Notes
**Date:** August 1, 2024

### Course Overview
This course provides an advanced exploration of secure programming principles, emphasizing the importance of security throughout the software development lifecycle. The course covers vulnerabilities, threat modeling, secure protocol design, and practical implementation techniques. It is designed for students with strong programming backgrounds who want to develop expertise in creating secure systems.

---

### Why Secure Programming? (The Critical Need)

#### Safety vs. Security in Different Domains
- **Aviation Safety Analogy**: 
  - In aviation, safety is prioritized above all else (e.g., delaying flights for safety checks)
  - *Example*: A flight was delayed 30 minutes due to suspected wheel issues, requiring emergency visas for passengers
  - *Key Insight*: "Safety is first" in aviation, but what about programming?

- **Programming Priorities Survey**:
  - Students ranked priorities as: **Maintainability (A)** > **Functionality (D)** > **Performance** > **Security (B)**
  - *Important Note*: While security is increasingly important, most students still prioritize maintainability and functionality first

#### Real-World Consequences of Insecure Programming

##### 1. **CrowdStrike Incident (2023)**
- **Cause**: Vulnerability in Windows update
- **Impact**: 
  - Blue Screen of Death (BSOD) across millions of systems
  - 2-day disruption to critical services (payments, transportation)
  - *Example*: "Many of my colleagues couldn't take the tram or train in Sydney or Melbourne"

##### 2. **Log4j Vulnerability (2021-2022)**
- **Cause**: Vulnerability in Apache Log4j library (used for logging)
- **Impact**:
  - Affected global systems using Java
  - Allowed remote code execution (attackers could gain full system control)
  - *Key Insight*: "A small building block inside a huge system. When it breaks, the whole system can collapse."

##### 3. **FrostyGoop Malware (2024)**
- **Target**: Industrial Control Systems (ICS) in Ukraine
- **Impact**:
  - Targeted ENCO controllers using Modbus TCP
  - Caused loss of heating services to 600+ apartment buildings (100,000 people)
  - Duration: 48 hours without heating/hot water
  - *Key Insight*: "Malware not only affects normal people but even large corporations with strict security policies"

#### Root Causes of Cyber Attacks
- **Vulnerabilities** stem from:
  - **Software** (most common)
  - **Hardware**
  - **Networks**
  - **Human factors** (weakest link in security)
- **Human Vulnerabilities**:
  - Developers not prioritizing security
  - Lack of security awareness
  - Clicking suspicious links (phishing)
  - *Mitigation*: University provides security training to raise awareness

#### Vulnerability Statistics
- **CVE (Common Vulnerabilities and Exposures)**:
  - Unique identifiers for vulnerabilities (e.g., CVE-2023-1234)
  - Format: `CVE-YEAR-NNNNN`
  - *Example*: `CVE-2023-1234` (2023, 1234th vulnerability reported)
- **Trend**: Number of vulnerabilities increasing exponentially since 2017
  - *Key Insight*: "Even if everyone learns secure programming, the number keeps increasing because software complexity grows exponentially"

---

### Course Structure & Content

#### Weekly Topics
| Week | Topic |
|------|-------|
| 1 | Introduction & Why Secure Programming |
| 2 | Security by Design & Threat Modeling |
| 3-4 | Memory-related vulnerabilities (C language) |
| 5 | Mitigation strategies for memory vulnerabilities |
| 6 | Race conditions in multi-threaded applications |
| 7 | Side channel attacks (hardware level) |
| 8-9 | Vulnerability testing (manual & automated) |
| 10 | Malware (including ransomware) |
| 11 | Security in SDLC (DevSecOps) |
| 12 | Review & Q&A |

#### Key Concepts Covered
- **Security by Design**: Incorporating security from the beginning of development
- **Threat Modeling**: Identifying potential threats and vulnerabilities early
- **Memory Management**: Understanding C's unsafe memory management
- **Race Conditions**: Issues in multi-threaded applications
- **Side Channel Attacks**: Exploiting hardware-level vulnerabilities (e.g., Meltdown, Spectre)
- **DevSecOps**: Integrating security throughout the software development lifecycle

---

### Course Prerequisites & Expectations

#### Required Skills
- **Strong programming skills**, including socket/network programming
- **Knowledge of C and assembly languages**
- **Understanding of operating systems** (memory management)
- *Note*: This is an **advanced course** with higher workload than typical courses

#### Course Materials
- **Required Textbook**: *Security Engineering: A Guide to Building Dependable Distributed Systems* by Ross Anderson (Dec 2020)
  - Library has online access

---

### Assessment Structure

#### Assessment Components
| Component | Weight | Details |
|-----------|--------|---------|
| **RangeForce Labs** | 30% | <ul><li>Undergrad: Parts 1 & 2 (15% each)</li><li>Postgrad: Parts 1, 2 & Challenges (10% each)</li></ul> |
| **Group Project** | 30% | Advanced Secure Protocol Design, Implementation and Review |
| **Final Exam** | 40% | <ul><li>Hurdle requirement: Must score â‰¥40% to pass</li><li>Format: Multiple choice, fill-in-the-blank, short answer</li></ul> |

#### Key Assessment Deadlines
| Component | Deadline |
|-----------|----------|
| RangeForce Part 1 | Week 5 (Undergrad) / Week 4 (Postgrad) |
| RangeForce Part 2 | Week 7 (Undergrad) / Week 6 (Postgrad) |
| Group Project: Initial Protocol Design | Week 2 |
| Group Project: Standardized Protocol | Week 4 |
| Group Project: Functional Prototype | Week 8 |
| Group Project: Inject Backdoors | Week 9 |
| Group Project: Peer Reviews | Week 10 |
| Group Project: Reflective Commentary | Week 11 |
| Group Project: Ethical Hackathon | Week 12 |

---

### RangeForce Platform Details

#### Platform Overview
- **Purpose**: Online learning platform for security fundamentals
- **Access**: Sent via university email in Week 3 (starting August 11)
- **Registration**:
  1. Click invitation email link
  2. Register using university email (axxxxxxx@adelaide.edu.au)
  3. Complete all modules (100% completion required)

#### Module Structure
- **Format**: Interactive modules with:
  - Concept explanations
  - Knowledge checks (automatically graded)
  - Feedback section (for RangeForce, not the course)
- **Completion**: 
  - Click "View Conclusion" when 100% complete
  - Click "End" to finalize module

#### Important Notes
- **Deadline**: Complete all modules by Week 8 (6 weeks total)
- **No Download Required**: Access via web browser
- **Feedback**: The feedback page is for RangeForce only, not for the course

---

### Group Project: Advanced Secure Protocol Design, Implementation and Review

#### Project Overview
- **Goal**: Design, implement, and evaluate a secure communication protocol for a distributed multi-party chat system
- **Key Requirements**:
  - No central server handling all communication
  - System must be robust to node/device failure
  - Must incorporate advanced secure coding practices
  - Must intentionally include ethical backdoors for peer review

#### Project Timeline
| Week | Milestone |
|------|-----------|
| 2 | Initial protocol design |
| 4 | Class-wide protocol standardization |
| 6 | Finalize implementation plans |
| 8 | Present functional prototype (deadline) |
| 9 | Inject ethical backdoors; submit final code |
| 10 | Peer code reviews (3 other groups) |
| 11 | Submit reflective commentary (group reflection) |
| 12 | Ethical hackathon (identify vulnerabilities) |

#### Key Project Requirements
1. **Protocol Design**:
   - Must be class-wide standard (not group-specific)
   - Must consider security aspects (encryption, authentication)
   - Must be robust to failures

2. **Implementation**:
   - Can use any language (C, Python, etc.)
   - Must incorporate secure coding practices
   - Must include **at least 2 intentional vulnerabilities/backdoors**

3. **Peer Review**:
   - Review 3 other groups' implementations
   - Use both manual and automated techniques
   - Provide constructive feedback

4. **Reflection**:
   - 2000 words (4 pages max)
   - Cover design process, implementation challenges, vulnerability detection
   - Include ethical considerations of backdoors
   - Discuss AI usage in development

#### Group Formation
- **Group Size**: 3-5 members
- **Deadline**: Form groups by Week 2 (August 20)
- **How to Form Groups**:
  1. Go to MyUni â†’ Project Groups
  2. Find existing groups or create new ones
  3. Add members to your group
- **Note**: Groups can include members from different cohorts (undergrad/postgrad) and workshops

---

### Policies & Important Notes

#### Late Submission Policy
| Days Late | Mark Reduction |
|-----------|----------------|
| â‰¤1 day | 75% (marks below 75% unaffected) |
| â‰¤2 days | 50% (marks below 50% unaffected) |
| â‰¤3 days | 25% (marks below 25% unaffected) |
| >3 days | 0% |

#### Extension Policy
- **Eligible Circumstances**: Medical, compassionate, or special circumstances
- **Process**:
  1. Submit online extension request form
  2. Attach supporting documentation
  3. Put `cms_extensions@adelaide.edu.au` as Course Coordinator
  4. Submit before deadline
  5. Notification within 3 business days

#### Academic Integrity & AI Usage
- **Core Principles**:
  - **Honesty**: Be honest about source of ideas
  - **Respect**: Give credit when using others' ideas
  - **Responsibility**: Take ownership of your work
  - **Fairness**: Treat others fairly
  - **Trust**: Do the right thing, even when no one's watching
  - **Courage**: Stand up for what's right

- **AI Usage Guidelines**:
  - Use AI "wisely" as an assistant
  - **Never** submit AI-generated content as your own
  - **Always** disclose AI usage in your work
  - **Key Insight**: "AI can only be an assistant. The main idea needs to come from you."

---

### Key Takeaways

1. **Security is Critical**: Insecure programming leads to real-world consequences (e.g., heating systems failing, financial losses)
2. **Security is Not an Afterthought**: Must be integrated from the design phase (Security by Design)
3. **This is an Advanced Course**: Requires strong programming skills and prior knowledge
4. **Group Project is Central**: Focuses on protocol design, secure implementation, and peer review
5. **RangeForce is Mandatory**: Complete all modules for 30% of your grade
6. **AI Usage Requires Discernment**: Use AI as an assistant, not a replacement for your own understanding
7. **Security is a Continuous Process**: Vulnerabilities increase exponentially as software complexity grows
8. **Human Factor is Critical**: "Human is the weakest link in security" - awareness is key

---

### Next Steps for Students

1. **Form a group** (3-5 members) on MyUni by Week 2
2. **Brush up on network/socket programming** knowledge
3. **Prepare to receive RangeForce invitation** in Week 3
4. **Discuss secure communication protocol** with your group
5. **Review sample exam** on MyUni (front page)

> "The most significant assessment component in this course is the final exam, which is worth 40%. And that's also a hurdle requirement embedded in it." - Dr. Triet Le


---

# Week 1: Attack Trees - Comprehensive Lecture Notes

<think>
Okay, the user wants me to create comprehensive academic notes from a lecture transcript about Attack Trees by Bruce Schneier. This is for Week 1 Introduction: Attack Trees, and I need to follow specific formatting requirements.

First, I'll analyze the transcript to identify the core concepts. The lecture introduces Attack Trees as a formal method for modeling security threats. Key elements include:
- The problem with current security terminology (e.g., "hacker proof software" being misleading)
- Attack tree structure (root = goal, leaves = attack methods)
- OR vs AND nodes (alternatives vs sequential steps)
- Value propagation (Boolean and continuous metrics like cost, probability)
- Practical examples (physical safe, PGP)
- Creation methodology and reuse benefits

I notice the transcript has several figures referenced (Fig 1-8), but since no slides are available, I'll describe the examples textually. The PGP example is particularly important as it demonstrates how attack trees reveal counterintuitive vulnerabilities (e.g., key length matters less than keyboard sniffers).

For structure, I'll organize around:
1. Core problem statement (why attack trees are needed)
2. Tree mechanics (nodes, values, propagation)
3. Practical applications (with safe/PGP examples)
4. Creation methodology
5. Strategic benefits (reusability, "what-if" analysis)

The user emphasized "no slides," so I'll avoid referencing figures directly. Instead, I'll describe the safe example in detail: "Goal: Open safe â†’ OR nodes: pick lock, learn combo, cut open, install improperly â†’ Learn combo requires AND: find written combo OR get from owner."

For the PGP section, I'll highlight the key insight: "Breaking RSA/IDEA is less likely than capturing keys via Back Orifice or keyboard sniffers." This contradicts common misconceptions about crypto strength.

I should include all value types mentioned:
- Boolean: Possible/impossible, expensive/not expensive
- Continuous: Cost (OR=cheapest child, AND=sum), probability, risk

The conclusion about security being a process (not product) is crucial - I'll make that a key takeaway.

For academic rigor, I'll:
- Define terms on first use (e.g., "AND node: requires all subgoals")
- Use bullet points for node types/values
- Add a "Key Insight" callout for the PGP revelation
- End with concrete takeaways like "Attack trees prioritize vulnerabilities by cost/probability"

I'll avoid adding external knowledge - strictly using transcript content. The "Dr. Dobb's Journal, Dec 1999" reference stays as historical context.

The title will be "Week 1: Attack Trees - Comprehensive Lecture Notes" with date placeholder. Overview summary will capture the essence: "Formal threat modeling method revealing counterintuitive vulnerabilities."

For study-friendliness, I'll:
- Bold key terms (e.g., **OR node**)
- Use consistent headers (## for main sections)
- Group examples under subheaders
- Include a "Why This Matters" section for the PGP case

Finally, the key takeaways will distill the lecture's core message: "Security is a process; attack trees provide reusable, scalable threat modeling."
</think>

**Date:** [Lecture Date]  
**Source:** Bruce Schneier, *Dr. Dobb's Journal*, December 1999  

---

### Overview  
This lecture introduces **Attack Trees** as a formal methodology for modeling security threats. Schneier argues that traditional security claims (e.g., "hacker-proof software") are misleading without context (e.g., *secure from whom? for how long?*). Attack Trees provide a structured way to:  
- Map all possible attack paths against a system  
- Quantify vulnerabilities using Boolean/continuous metrics  
- Prioritize countermeasures based on attacker capabilities and goals  
- Reuse threat models across systems (scalability)  

> **Core Insight**: Security is a *process*, not a product. Attack Trees reveal that perceived vulnerabilities (e.g., key length in cryptography) are often irrelevant compared to easier attack vectors (e.g., keylogging).  

---

### Key Concepts & Definitions  

#### 1. **Attack Tree Structure**  
- **Root Node**: Primary attack goal (e.g., "Open safe," "Read PGP-encrypted message").  
- **Leaf Nodes**: Atomic attack methods (e.g., "Pick lock," "Bribe owner").  
- **OR Nodes**: *Alternatives* (any path succeeds).  
  > *Example*: To open a safe, attackers can *pick the lock* **OR** *learn the combination* **OR** *cut open the safe*.  
- **AND Nodes**: *Sequential steps* (all paths required).  
  > *Example*: To eavesdrop on a combination, attackers must *eavesdrop on conversation* **AND** *get owner to reveal combination*.  

#### 2. **Value Propagation**  
Nodes are assigned values (Boolean or continuous) that propagate up the tree:  
| **Node Type** | **Boolean Propagation**       | **Continuous Propagation** |  
|---------------|-------------------------------|----------------------------|  
| **OR Node**   | `Possible` if *any* child is `Possible` | `Cheapest` child value |  
| **AND Node**  | `Possible` only if *all* children are `Possible` | `Sum` of child values |  

> **Example**:  
> - *Boolean*: If "Cut safe" (OR child) is `Possible`, root is `Possible`.  
> - *Cost (Continuous)*: For "Learn combination" (AND node), cost = `Find written combo` cost + `Get from owner` cost.  

---

### Practical Examples & Case Studies  

#### **Example 1: Physical Safe Attack Tree**  
*(Figures 1â€“5 referenced in transcript)*  
- **Goal**: Open safe.  
- **OR Paths**:  
  - Pick lock  
  - Learn combination (via OR: *find written combo* **OR** *bribe owner*)  
  - Cut open safe  
  - Install improperly  
- **Key Insight**:  
  > "The cheapest attack costing <$100,000 is *bribing the owner* (Fig 5). If safe contents are worth <$100k, this is the critical vulnerability."  

#### **Example 2: PGP E-Mail Security**  
*(Figures 7â€“8 referenced in transcript)*  
- **Goal**: Read a message encrypted with PGP.  
- **Critical Vulnerabilities (Not Crypto Breaks)**:  
  - Capture screen during decryption (Trojan, TEMPEST)  
  - Steal private key (Back Orifice, virus)  
  - Recover passphrase (keylogger, TEMPEST)  
  - Brute-force weak passphrase (vs. 128-bit IDEA keys)  
- **Key Insight**:  
  > "Breaking RSA/IDEA *is not the primary threat*. Key length (1024-bit vs. 2048-bit) is irrelevant compared to *easier attacks* like keylogging. Increasing key length is like 'putting a stake in the ground'â€”ineffective against actual threats."  

---

### Creating & Using Attack Trees  

#### **Step-by-Step Creation**  
1. **Define attack goals** (e.g., "Read PGP message," "Forge signature").  
2. **Brainstorm all attack paths** for each goal (add leaf nodes).  
3. **Decompose recursively** (e.g., "Learn combination" â†’ "Find written combo" **OR** "Bribe owner").  
4. **Validate with peers** (have others add missing nodes; repeat over months).  
5. **Assign node values** (research required):  
   - Boolean: `Possible`/`Impossible`, `Expensive`/`Not expensive`  
   - Continuous: Cost, probability, risk, skill required  

#### **Strategic Applications**  
| **Use Case**                          | **How Attack Trees Help**                                                                 |  
|---------------------------------------|-----------------------------------------------------------------------------------------|  
| **Prioritize countermeasures**        | Identify cheapest/most likely attack (e.g., *bribe owner* for safe, *keylogger* for PGP). |  
| **"What-if" analysis**                | Simulate countermeasures (e.g., *raise bribe cost from $20k â†’ $80k* â†’ safe cost rises from $20k â†’ $60k). |  
| **Assess security assumptions**       | Reveal hidden assumptions (e.g., "PGP security assumes *no one can bribe programmers*"). |  
| **Compare attacks**                   | Rank by cost, probability, skill (e.g., "Cheapest attack requiring *no special equipment*"). |  
| **Reuse across systems**              | Embed attack trees into larger models (e.g., PGP tree â†’ part of *computer system* tree in Fig 8). |  

---

### Why Attack Trees Matter: Critical Insights  

#### **1. Counterintuitive Vulnerabilities**  
> "People worry about *key length* in PGP, but attack trees show itâ€™s *irrelevant*. The real threat is *capturing keys via Back Orifice*â€”a 100x easier attack."  

#### **2. Attacker-Centric Analysis**  
- **Organized crime**: Worry about *expensive attacks* (e.g., $80k bribes).  
- **Terrorists**: Worry about *high-risk attacks* (e.g., suicide bombers).  
- **Graduate students**: Worry about *low-skill attacks* (e.g., brute-forcing weak passphrases).  
> *Key Point*: "Your attackerâ€™s *motivations, skills, and resources* determine which tree branches matter."  

#### **3. Scalability & Reusability**  
- **No need to be an expert**:  
  - *PGP user* only needs root node value ("cost to read message").  
  - *Security expert* only needs root node value for *safe* ("cost to open safe").  
- **Library of attack trees**: Reuse models for programs, locks, protocols (e.g., "PGP attack tree" â†’ part of "network security" tree).  

---

### Conclusion & Key Takeaways  

#### **Why Attack Trees Are Revolutionary**  
- **Formalizes threat modeling**: Moves beyond vague claims ("secure") to quantifiable analysis.  
- **Reveals hidden weaknesses**: Exposes that *easiest attacks* (not strongest crypto) dominate security risks.  
- **Enables proactive defense**: "Play what-if" games to test countermeasures *before* breaches occur.  
- **Scales across systems**: Reusable library reduces expertise silos (critical for agencies like NSA).  

#### **Final Summary**  
> **Security is a process, not a product. Attack Trees provide the methodology to:  
> (1) Map all attack paths,  
> (2) Quantify vulnerabilities by cost/probability,  
> (3) Prioritize defenses against *real* threats (not perceived ones),  
> (4) Reuse insights across systems.**  

---

### Key Takeaways for Study  
1. **OR vs. AND nodes**: OR = *any path works*; AND = *all steps required*.  
2. **Value propagation**: OR nodes take *best* child value; AND nodes *sum* child values.  
3. **PGP lesson**: *Key length is irrelevant*â€”focus on *key capture* (e.g., keyloggers).  
4. **Attacker profiling**: Tailor defenses to *attacker type* (e.g., terrorists vs. students).  
5. **Reusability**: Attack trees are *modular*â€”embed small trees (e.g., PGP) into larger systems.  
6. **Security mindset**: "Secure from *whom*? For *how long*? At *what cost*?"  

> **Schneierâ€™s Closing Thought**:  
> "Increasing key length from 1024-bit to 2048-bit is like *putting a stake in the ground*â€”itâ€™s a distraction from the *palisade* (real defenses) that actually matter."


---

# Chapter 27: Secure Systems Development - Safety Critical Systems (Week 1 Introduction)

<think>
We are creating comprehensive study notes for Chapter 27: Safety Critical Systems (Week 1 Introduction) from the textbook.

The chapter content is provided in 9 slides (from Slide 1 to Slide 9). We'll structure the notes to follow the chapter's flow.

Key sections we see in the slides:
- Introduction to safety-critical systems and their relevance to security
- Safety engineering methodologies (27.3.1)
- Hazard analysis (27.3.2)
- Fault trees and threat trees (27.3.3)
- Failure modes and effects analysis (FMEA) (27.3.4)
- Threat modeling (27.3.5)
- Quantifying risks (27.3.6)

We'll also note the case studies and examples provided.

Let's break down the notes accordingly.

Important: We must extract all key information, define terms, and structure for exam preparation.

We'll start with:
- Chapter title and a brief overview (since learning objectives aren't explicitly stated, we'll infer from the content)
- Then, we'll go through each section in order.

We note that the chapter is from "Anderson c27.tex", and the page numbers are provided (e.g., Page 969, 970, etc.), but we won't include page numbers in the notes unless they are critical for reference (which they aren't for study notes).

We'll create:
- Hierarchical headers
- Bold key terms
- Bullet points for lists
- Tables for comparisons (if any)
- Blockquotes for key insights
- Summary boxes for complex concepts
- A comprehensive summary at the end
- Review questions (if any are mentioned; we don't see any in the provided text, so we'll skip or create a few based on the content)

Let's begin.

Note: The chapter is titled "27.3 Lessons from safety-critical systems", but the overall chapter is "Chapter 27: Secure Systems Development". We'll use the chapter title as given.

We'll structure the notes as:


### Learning Objectives
* Understand the principles of safety-critical systems and their relevance to security engineering.
* Learn key methodologies from safety engineering (hazard analysis, fault trees, FMEA) and how they apply to security.
* Recognize the importance of integrating safety and security from the design phase.
* Analyze case studies of failures in safety-critical systems and their lessons for security.

### Key Concepts and Definitions

#### Safety-Critical Systems
- Systems in which a certain class of failure must be avoided at all costs.
- Examples: flight controls, automatic braking systems.
- **Criticality classes**: safety-critical, business-critical, security-critical, critical to the environment.

#### Safety Case
- A structured argument that provides evidence that a system is safe to operate.
- Typically includes: hazard analysis, safety functional and integrity requirements, test results (component and system level).
- Required for regulatory compliance and to demonstrate due care in case of failure.

#### Hazard Elimination
- The process of designing hazards out of a system completely.
- Example: In motor reversing circuits, swapping battery and motor to avoid shorting the battery (Slide 3).

#### Fault Tree Analysis (FTA)
- A top-down method to identify failures that could cause accidents.
- Root: undesired behavior; nodes: possible causes.
- In security, called **Threat Tree**.

#### Failure Modes and Effects Analysis (FMEA)
- A bottom-up method to trace the consequences of component failures to system effects.
- Pioneered by NASA.
- Focuses on failure modes, their effects, and severity.

#### Threat Modeling
- Systematic process to identify, quantify, and address threats to a system.
- Microsoft's approach: meet-in-the-middle (combines top-down and bottom-up).

#### Quantifying Risks
- Using statistical methods to measure failure rates, error rates, etc.
- **Human Error**: Depends on task familiarity, complexity, pressure, and cues (e.g., error rate 1 in 100,000 for simple, frequent tasks).

#### Safety Usability
- Designing systems so that in emergencies, operators can make safe decisions.
- Principles: default to safe state, keep information and controls simple and intuitive.

#### Fault Masking
- When a system continues to function after a fault (e.g., majority voting), but the safety margin is reduced and the fault may not be visible to operators.

### Detailed Study Notes

#### 27.3 Lessons from Safety-Critical Systems

##### Introduction
- Safety-critical systems are those where a specific class of failure must be avoided (e.g., flight controls, automatic braking).
- The safety engineering literature offers methodologies that can be adapted to security engineering.
- **Key Insight**: Safety deals with random failures; security deals with hostile adversaries who can cause failures at the worst time.

> "Safety engineering is not just about correct operation, but about correct failure too." (Slide 3)

##### 27.3.1 Safety Engineering Methodologies
- **Systematic approach**: from safety analysis to specification to product, building safety in from the start (not retrofitting).
- **Procedure**:
  1. Identify hazards and assess risks.
  2. Decide on strategy (avoidance, constraint, redundancy).
  3. Trace hazards to critical hardware/software components.
  4. Identify critical operator procedures (considering psychology and operations research).
  5. Set safety functional requirements (what safety mechanisms must do).
  6. Set safety integrity requirements (likelihood of safety function being performed satisfactorily).
  7. Decide on test plan (integrated part of safety case).
- **Standards**:
  - ISO 61508: Basic safety framework for programmable electronics (e.g., chemical plant controls).
  - ISO 26262: For road vehicles (extended from ISO 61508).

> **Safety Case**: Evidence for due care; includes hazard analysis, requirements, test results. Must be maintained (not sidelined after approval).

##### 27.3.2 Hazard Analysis
- **Goal**: Eliminate hazards where possible.
- **Example: Motor Reversing Circuit** (Figure 27.2):
  - Original design (a): Double-pole double-throw switch. If one pole fails, battery shorts â†’ fire.
  - Modified design (b): Swap battery and motor. Switch failure only shorts motor (not battery) â†’ safer.
- **Application to Security**:
  - Minimize trusted computing base (TCB). Example: SWIFT design (Section 12.3.2) â€“ keys exchanged directly between banks, so SWIFT didn't need to be trusted.
- **Application to Privacy**:
  - Central database for contact tracing â†’ privacy hazard.
  - Alternative: Keep Bluetooth contact history on mobile phones â†’ better privacy.

> **Key Principle**: "Minimizing the trusted computing base is an exercise in hazard elimination."

##### 27.3.3 Fault Trees and Threat Trees
- **Fault Tree Analysis (FTA)**:
  - Top-down: Root = undesired behavior; nodes = causes.
  - Used in safety engineering.
- **Threat Tree** (in security):
  - Same structure but for security threats.
  - Example: Fraud from ATMs (Figure 27.3) â€“ shows attack paths (shoulder surfing, cryptanalysis, etc.).
- **DoD Requirement**: Threat trees are used and can be highly classified.
- **Benefits**:
  - Visualize commonality between attack paths.
  - Reason about disrupting most attacks with least effort.
  - Can include countermeasures (with sub-branches).

> **Insight**: "A threat tree can amount to an attack manual for the system."

##### 27.3.4 Failure Modes and Effects Analysis (FMEA)
- **Bottom-up approach** (tracing from component failure to system effect).
- **Pioneered by NASA** for aerospace.
- **Process**:
  - Identify each component's failure modes.
  - Trace effects up to mission impact.
  - Prioritize based on severity and likelihood.
- **Case Study: Challenger Disaster (1986)**:
  - O-rings in booster rockets: known risk (damage on previous flights), contractor knew cold increased risk.
  - Concerns didn't reach top management.
  - O-ring became brittle in cold â†’ failed â†’ shuttle lost.
  - **Lesson**: Failures are not just technical but involve organizational behavior (e.g., communication across institutional boundaries).

> **Key Insight**: "When protection mechanisms cross institutional boundaries, you need to think of the law and economics as well as just the engineering."

##### 27.3.5 Threat Modeling
- **Challenge**: FTA and FMEA are hard to automate and can be disrupted by subtle changes.
- **Microsoft's Approach (2003)**:
  - **Meet-in-the-middle**: Combines top-down and bottom-up.
  - Steps:
    1. List assets to protect (e.g., transaction ability, confidential data).
    2. List assets available to attacker (e.g., ability to subscribe, manipulate inputs).
    3. Trace attack paths through the system.
    4. Identify trust levels, barriers, and techniques (spoofing, tampering, etc.).
  - **Use in SDLC**: Architecture reviews, code reviews, penetration tests.
- **Managing Data**:
  - **Matrix Approach**: Hazards vs. safety mechanisms; require at least two independent mechanisms per serious hazard.
  - **System Theoretic Process Analysis (STPA)**: Starts with hazards and designs controls top-down; helps with interacting control loops.

> **Key Insight**: "Modern large-scale systems are typically designed to limit damage if a single component is compromised."

##### 27.3.6 Quantifying Risks
- **Failure Rate Measurement**:
  - Component failure rates: statistical.
  - Software bugs: tracked by techniques (to be discussed in next chapter).
  - Operator error: depends on task familiarity, complexity, pressure, cues.
- **Error Rate Examples**:
  - Simple, frequent task: 1 in 100,000 operations.
  - Complex, first-time task under pressure: high error probability (e.g., Three Mile Island, Chernobyl).
- **Safety Usability Principles**:
  - **Default to safe state**: e.g., damp nuclear reaction, return aircraft to level flight, stop autonomous vehicle.
  - **Keep information and controls simple and intuitive**.
    - *Aviation Example*: Old planes had 6 critical instruments in center; new planes have 50 alarms â†’ pilots overwhelmed (USS McCain collision, 2017).
- **Human Factors**:
  - Errors rare in frequent tasks (with skill); more likely under stress and surprise.
  - **Security Usability**: Present risks in line with common mental models; design for stress-induced reactions.

> **Case Study: Boeing 737Max**:
  - **Failure**: Flight control software relied on single angle-of-attack sensor (instead of two).
  - **Cause**: Engineers under time pressure assumed pilots could cope with failure (skipped FMEA).
  - **Result**: Two crashes due to faulty sensor â†’ plane dived.
  - **Lesson**: "Satan's computer" (security engineering) is harder to test than "Murphy's computer" (safety engineering).

> **Key Insight**: "A safety engineer will certify a critical flight-control system with an MTBF of 10^9 hours; a security engineer has to worry whether an adversary can force the preconditions for that one-in-a-billion failure and crash the plane on demand."

##### 27.3.7 Integration of Safety and Security
- **Critical Difference**:
  - Safety: random failures.
  - Security: hostile adversary (can cause failures at worst time).
- **Lesson**: "Safety has to be built in as a system is developed, rather than retrofitted." (Same for security.)
- **Modern Shift**: Move from project-based to agile/DevSecOps to embed security in product evolution.

> **Key Insight**: "The main difference between safety and security is in the failure model."

### Summary of Key Methodologies

| Methodology          | Approach      | Key Focus                          | Security Application          |
|----------------------|---------------|------------------------------------|-------------------------------|
| **Fault Tree (FTA)** | Top-down      | Causes of undesired behavior       | Threat Tree for security threats |
| **FMEA**             | Bottom-up     | Component failure effects          | Threat modeling with insider risks |
| **Threat Modeling**  | Meet-in-middle| Asset-based attack paths           | Microsoft's approach          |
| **Safety Case**      | Integrated    | Evidence for due care              | Security case for compliance  |

### Summary Box: Safety vs. Security Engineering

- **Safety Engineering**:
  - Focus: Avoiding random failures (e.g., component failure, human error).
  - Certification: Based on statistical failure rates (e.g., MTBF 10^9 hours).
  - Example: Flight control system.

- **Security Engineering**:
  - Focus: Defending against hostile adversaries (who can cause failures at worst time).
  - Certification: Must consider if adversary can force failure conditions.
  - Example: "Programming Satan's computer" â€“ designing for maliciously wrong answers at worst moment.

> **Core Insight**: "Security engineering is hard because Satan's computer is harder to test."

### Comprehensive Summary

Safety-critical systems engineering provides valuable methodologies for security engineering. Key lessons include:
1. **Build safety/security in from the start** (not retrofit).
2. **Hazard elimination** (e.g., minimizing TCB) is a powerful principle.
3. **Systematic analysis** (FTA, FMEA, threat trees) helps identify and mitigate risks.
4. **Quantify risks** using statistical methods and human factors.
5. **Design for usability in emergencies** (simple controls, default safe state).
6. **Integrate safety/security into the product lifecycle** (DevSecOps).

Critical failures (e.g., Challenger, Boeing 737Max) highlight the importance of:
- Organizational communication (across institutional boundaries).
- Not skipping safety analysis (FMEA) under time pressure.
- Considering both technical and human factors.

Security engineering must account for **hostile adversaries** (unlike safety's random failures), making it more challenging. The goal is to design systems that are resilient even when an adversary actively tries to cause failure.

### Review Questions (Based on Chapter Content)

1. What is the main difference between safety engineering and security engineering in terms of failure models?
2. Describe the process of hazard elimination with an example from the chapter.
3. How does a threat tree differ from a fault tree, and what is its purpose in security engineering?
4. Explain the Challenger disaster in terms of FMEA and organizational behavior.
5. Why is it important to integrate safety cases with mainstream product documentation?
6. What is "fault masking" and why is it a concern in redundant systems?
7. How does the Boeing 737Max case illustrate the challenges of security engineering compared to safety engineering?

---

Now, we'll format the above into a well-structured markdown document.
</think>

# Chapter 27: Secure Systems Development - Safety Critical Systems (Week 1 Introduction)

### Learning Objectives
- Understand principles of safety-critical systems and their relevance to security engineering
- Apply safety engineering methodologies (hazard analysis, FMEA, threat modeling) to security contexts
- Analyze case studies of safety/security failures and their lessons
- Recognize the importance of integrating safety/security from design phase
- Quantify risks using safety engineering techniques
- Design for safety usability in emergency scenarios

---

### Key Concepts & Definitions

| Term | Definition | Relevance to Security |
|------|------------|----------------------|
| **Safety-Critical Systems** | Systems where a specific class of failure must be avoided at all costs | Foundation for security engineering principles |
| **Safety Case** | Structured argument providing evidence that a system is safe to operate | Required for regulatory compliance; includes hazard analysis, requirements, test results |
| **Hazard Elimination** | Designing hazards out of a system completely | Minimizing trusted computing base (e.g., SWIFT design) |
| **Fault Tree Analysis (FTA)** | Top-down method identifying failures causing accidents | Security adaptation: **Threat Tree** |
| **Failure Modes & Effects Analysis (FMEA)** | Bottom-up method tracing component failures to system effects | Security adaptation: Threat modeling with insider risks |
| **Safety Integrity Requirements** | Specification of failure rate likelihood for safety functions | Security equivalent: Threat tolerance levels |
| **Fault Masking** | System continues functioning after failure (e.g., majority voting), but safety margin eroded | Critical in redundant security systems |
| **Satan's Computer** | Security engineering challenge: Programming for maliciously wrong answers at worst moment | Core difference from safety engineering ("Murphy's computer") |

> **Key Insight**: *"Safety engineering is not just about correct operation, but about correct failure too."* (Slide 3)

---

### 27.3 Lessons from Safety-Critical Systems

#### Introduction: Safety vs. Security Engineering
- **Safety Engineering**: Deals with *random failures* (e.g., component malfunction, human error)
- **Security Engineering**: Deals with *hostile adversaries* who can cause failures at worst possible time
- **Critical Difference**:  
  > *"A safety engineer will certify a critical flight-control system with an MTBF of 10â¹ hours; a security engineer has to worry whether an adversary can force the preconditions for that one-in-a-billion failure and crash the plane on demand."*

> **Core Principle**: *"Programming Satan's computer is harder to test than programming Murphy's."* (Slide 9)

---

#### 27.3.1 Safety Engineering Methodologies
**Systematic Approach (Build-in from Start)**:
1. Identify hazards and assess risks
2. Decide on strategy (avoidance, constraint, redundancy)
3. Trace hazards to critical hardware/software components
4. Identify critical operator procedures (psychology/operations research)
5. Set safety functional requirements (what safety mechanisms must do)
6. Set safety integrity requirements (failure rate likelihood)
7. Develop integrated test plan (part of safety case)

**Key Standards**:
- **ISO 61508**: Basic safety framework for programmable electronics (e.g., chemical plant controls)
- **ISO 26262**: Specialized standard for road vehicles (extended from ISO 61508)

> **Critical Insight**: *"The safety case must be integrated with mainstream product documentation. If separate, it's easily sidelined after approval."* (Slide 9)

---

#### 27.3.2 Hazard Analysis
**Goal**: Eliminate hazards where possible before design.

**Motor Reversing Circuit Example** (Figure 27.2):
| Design | Risk | Solution |
|--------|------|----------|
| Double-pole switch (left) | Single pole failure â†’ battery short â†’ fire | Swap battery/motor (right) â†’ switch failure only shorts motor |

**Security Applications**:
- **SWIFT Design (Section 12.3.2)**:  
  *Keys exchanged directly between banks â†’ SWIFT minimized trust â†’ hazard elimination*
- **Privacy Engineering**:  
  *Central database (privacy hazard) vs. Bluetooth contact history on mobiles (better privacy)*

> **Key Principle**: *"Minimizing the trusted computing base is an exercise in hazard elimination."*

---

#### 27.3.3 Fault Trees & Threat Trees
**Fault Tree Analysis (FTA)**:
- Top-down approach: Root = undesired behavior â†’ causes
- Used in safety engineering

**Threat Tree (Security Adaptation)**:
- Same structure but for security threats
- Example: ATM fraud threat tree (Figure 27.3) shows attack paths (shoulder surfing, cryptanalysis, etc.)

**Benefits**:
- Visualize commonality between attack paths
- Identify most efficient disruption points
- Can include countermeasures (sub-branches)

> **DoD Requirement**: *"A threat tree can amount to an attack manual for the system."*

---

#### 27.3.4 Failure Modes & Effects Analysis (FMEA)
**Bottom-Up Approach**:
- Trace component failures â†’ system effects
- Pioneered by NASA for aerospace

**Process**:
1. Identify component failure modes
2. Trace effects to mission impact
3. Prioritize based on severity/likelihood

**Case Study: Challenger Disaster (1986)**:
- **Failure**: O-rings became brittle in cold â†’ failed
- **Root Cause**:  
  *NASA project manager knew O-ring risk, contractor knew cold increased risk, but concerns didn't cross institutional boundaries*
- **Lesson**: *"Failures are not just technical but involve organizational behavior."*

> **Critical Insight**: *"When protection mechanisms cross institutional boundaries, you need to think of law and economics as well as engineering."*

---

#### 27.3.5 Threat Modeling
**Microsoft's Meet-in-the-Middle Approach** (Post-2003 security push):
1. List assets to protect (e.g., transaction ability, confidential data)
2. List attacker assets (e.g., subscription ability, input manipulation)
3. Trace attack paths through system
4. Identify trust levels, barriers, and techniques (spoofing, tampering, etc.)

**Data Management Techniques**:
| Method | Description | Security Application |
|--------|-------------|----------------------|
| **Matrix Approach** | Hazards vs. safety mechanisms; require â‰¥2 independent mechanisms per hazard | Verify defense-in-depth |
| **STPA** | Top-down hazard â†’ control design | Tease apart interacting control loops |

> **Key Insight**: *"Modern large-scale systems are designed to limit damage if a single component is compromised."*

---

#### 27.3.6 Quantifying Risks
**Risk Quantification Methods**:
- Component failure rates: Statistical measurement
- Software bugs: Trackable via metrics
- Operator error: Depends on:
  - Task familiarity & complexity
  - Pressure level
  - Cues to success

**Error Rate Examples**:
| Task Type | Error Rate | Example |
|-----------|------------|---------|
| Simple, frequent | 1 in 100,000 | Routine operation |
| Complex, first-time under pressure | High | Three Mile Island, Chernobyl |

**Safety Usability Principles**:
1. **Default to safe state**:  
   *Damp nuclear reaction â†’ return aircraft to level flight â†’ stop autonomous vehicle*
2. **Keep information/simple controls**:  
   *Old planes: 6 critical instruments centered; New planes: 50 alarms â†’ pilot overload (USS McCain collision, 2017)*

**Boeing 737Max Case Study**:
- **Failure**: Relied on single angle-of-attack sensor (instead of two)
- **Cause**: Engineers skipped FMEA under time pressure â†’ assumed pilots could cope
- **Result**: Two crashes due to faulty sensor â†’ plane dived
- **Lesson**: *"Satan's computer is harder to test than Murphy's computer."*

> **Critical Insight**: *"Security usability isn't just about intuitive interfacesâ€”it must present risks in line with common mental models of threat."*

---

### Summary Box: Safety vs. Security Engineering

| Aspect | Safety Engineering | Security Engineering |
|--------|-------------------|----------------------|
| **Failure Model** | Random failures (component, human) | Hostile adversary causing failures at worst time |
| **Certification Basis** | Statistical failure rates (e.g., MTBF 10â¹ hours) | Adversary's ability to force failure conditions |
| **Core Challenge** | Avoiding rare random failures | Defending against maliciously timed failures |
| **Testing Difficulty** | "Programming Murphy's computer" | "Programming Satan's computer" (harder to test) |
| **Key Principle** | Build safety in from start | Build security in from start |

> **Final Insight**: *"Safety has to be built in as a system is developed, rather than retrofitted. The main difference between safety and security is in the failure model."*

---

### Comprehensive Summary

Safety-critical systems engineering provides essential methodologies for security engineering. Key principles include:
1. **Hazard elimination** (e.g., minimizing trusted computing base) is foundational
2. **Systematic analysis** (FTA, FMEA, threat trees) must be integrated from design phase
3. **Quantify risks** using statistical methods and human factors (error rates depend on task complexity/pressure)
4. **Design for safety usability**: Default to safe state, keep controls simple during emergencies
5. **Integrate safety cases** with mainstream documentation (avoiding post-approval neglect)
6. **Recognize adversary difference**: Security requires defending against *maliciously timed failures* (Satan's computer), making it fundamentally harder than safety engineering

**Critical Lessons from Failures**:
- **Challenger**: Organizational communication failures across institutional boundaries
- **Boeing 737Max**: Skipping FMEA under time pressure â†’ catastrophic failure
- **USS McCain**: UI overload â†’ pilot confusion â†’ collision

**Modern Shift**: Moving from project-based to **DevSecOps** to embed security in product evolution.

---

### Review Questions

1. **Explain the difference between safety engineering and security engineering in terms of failure models.**  
   *Safety deals with random failures (e.g., component malfunction); security deals with hostile adversaries who can cause failures at worst possible time.*

2. **Describe hazard elimination with a security example from the chapter.**  
   *SWIFT design: Keys exchanged directly between banks (not through SWIFT), minimizing trusted computing base and eliminating trust hazards.*

3. **How does a threat tree differ from a fault tree?**  
   *Threat trees are security adaptations of fault trees; they map attack paths (e.g., ATM fraud) instead of technical failures.*

4. **Why was the Challenger disaster a failure of FMEA?**  
   *O-ring risk was known to project manager and contractor, but concerns didn't cross institutional boundaries â†’ FMEA wasn't properly integrated.*

5. **What is "fault masking" and why is it dangerous?**  
   *When a system continues functioning after a fault (e.g., majority voting), but safety margin erodes. Operators may not recognize the degraded state under pressure (e.g., aircraft with one system offline).*

6. **Why is security engineering harder than safety engineering?**  
   *Security requires defending against "Satan's computer" (maliciously wrong answers at worst moment), while safety deals with "Murphy's computer" (random failures). Satan's computer is harder to test.*

7. **How should safety cases be managed to prevent failures like Boeing 737Max?**  
   *Integrate safety cases with mainstream documentation and update them continuously (not sideline after approval).*

---

> **Final Exam Tip**: Always connect safety engineering principles to security applications. Remember the **Satan's computer** concept as the core differentiator in security engineering challenges.


---

# Chapter 2: Who Is The Opponent?

<think>
I need to create comprehensive study notes from the textbook chapter "Who Is The Opponent" from Chapter 2 of "Security Engineering: A Guide to Building Dependable Distributed Systems" by Ross Anderson.

Let me analyze the chapter content and structure to create well-organized study notes.

The chapter is about identifying and understanding different types of adversaries or opponents in cybersecurity. The author categorizes adversaries into four main groups:
1. Spies (government intelligence agencies)
2. Crooks (cybercriminals)
3. Geeks (security researchers)
4. The swamp (abuse against people, like cyberbullying)

Let me structure my notes to follow this categorization, with appropriate subheadings for each category.

I'll include:
- Key definitions
- Important examples and case studies
- Historical context
- Technical details about attacks and defenses
- Summary boxes for complex concepts
- Review questions (if any)

Let me start by creating the main structure for the notes.

First, I'll create a header with the chapter title and learning objectives (though the chapter doesn't explicitly state learning objectives, I'll infer them from the content).

Then I'll create sections for each of the four main categories of adversaries, with subsections for the important details within each category.

I'll include key terms in bold, important case studies with details, and create summary boxes for complex concepts.

Let me now extract all the key information from the chapter to create comprehensive notes.

Key points from the chapter:

1. Introduction: The importance of identifying opponents before designing security systems.

2. Spies (Government Intelligence Agencies):
   - Five Eyes (USA, UK, Canada, Australia, New Zealand)
   - Programs like Prism, Tempora, Muscular, Xkeyscore, Bullrun, Edgehill
   - Examples: Snowden revelations, Operation Socialist (GCHQ against Sony), Stuxnet
   - Attribution challenges

3. Crooks (Cybercriminals):
   - Criminal infrastructure (botnets, malware writers, spam senders, cashout gangs)
   - Types of attacks: phishing, ransomware, card fraud, business email compromise
   - Underground markets and specialization
   - Examples: Equifax hack, Mirai botnet, Wannacry

4. Geeks (Security Researchers):
   - Responsible disclosure practices
   - Bug bounty programs
   - Ethical considerations
   - Examples: Researchers who discovered vulnerabilities in banking systems

5. The Swamp (Abuse against People):
   - Cyberbullying
   - Hate campaigns and hacktivism
   - Child sex abuse material (CSA)
   - Intimate partner abuse
   - Examples: Gamergate, Operation Ore

Now I'll create the detailed notes following this structure.

I'll include key terms, definitions, examples, and important case studies with details.

Let me create the notes in the required format.
</think>


### Learning Objectives
- Understand the four main categories of adversaries in cybersecurity
- Identify key characteristics of each adversary type
- Analyze historical case studies of attacks by each category
- Recognize the importance of threat modeling in security design
- Understand the evolving nature of cybercrime and cyberwarfare

---

### 2.1 Introduction: The Importance of Identifying Opponents

**Key Concept**: *Threat modeling* is the process of identifying potential adversaries and understanding their capabilities, motivations, and methods before designing security systems.

> "The systems you build or operate can be attacked by a wide range of opponents. It's important to work out who might attack you and how, and it's also important to be able to figure out how you were attacked and by whom."

**Historical Context**: 
- Early security focused on physical threats and simple computer security
- As systems became interconnected, the range of potential adversaries expanded dramatically
- The rise of the internet and mobile computing created new attack surfaces

**Critical Insight**: 
> "It's not enough to think about usability; you need to think about *abusability* too."

---

### 2.2 Spies: Government Intelligence Agencies

#### Key Characteristics
- **Motivation**: National security, economic advantage, political influence
- **Capabilities**: Advanced technical resources, legal authority, long-term patience
- **Methods**: Covert surveillance, network infiltration, supply chain compromise

#### Major Programs and Operations

| Program/Operation | Description | Key Details |
|-------------------|-------------|-------------|
| **Prism** | Mass collection of internet communications | Secretly collected data from major tech companies (Google, Facebook, etc.) |
| **Tempora** | Bulk collection of internet traffic | Collected data from fiber optic cables passing through UK |
| **Muscular** | Targeted collection from data centers | Compromised Google and Yahoo data centers |
| **Xkeyscore** | Real-time global data collection | Allowed analysts to search through vast databases of communications |
| **Bullrun** | Cryptanalysis program | Aimed at breaking encryption standards |
| **Edgehill** | Similar to Bullrun | UK counterpart to Bullrun |

#### Case Studies

**Snowden Revelations (2013)**:
- Edward Snowden leaked classified NSA documents
- Revealed global surveillance programs including PRISM, TEMPORA, and MUSCULAR
- Demonstrated the scale of government surveillance capabilities

**Operation Socialist (GCHQ vs. Sony)**:
- GCHQ (UK intelligence agency) compromised Sony's network
- Targeted Sony's email system to gather intelligence
- Example of intelligence agencies using cyber operations against private companies

**Stuxnet (2010)**:
- Sophisticated cyber weapon targeting Iran's nuclear program
- First known cyber weapon to cause physical damage
- Demonstrated state-level cyber warfare capabilities

#### Attribution Challenges

> "It's often said that cyber is different, because attribution is hard. As a general proposition this is untrue; anonymity online is much harder than you think."

**Key Insight**: 
- Anonymity online is harder than it seems
- Smart people make operational security mistakes that give them away
- Threat intelligence companies have compiled data enabling attribution with reasonable probability

**Case Study: Climategate (2009)**:
- Over 1,000 emails from climate scientists at University of East Anglia were leaked
- Climate skeptics claimed evidence of a global conspiracy
- Analysis suggested it was likely an internal leak or accident (filename "FOIA2009.zip" suggested it was prepared for freedom-of-information disclosure)

**Case Study: Equifax Hack (2017)**:
- 145.5 million Americans' personal information stolen
- Initially appeared to be a criminal hack
- Later analysis suggested Chinese military members were indicted for the attack
- Highlighted the blurred lines between criminal and state-sponsored attacks

---

### 2.3 Crooks: Cybercriminals

#### Key Characteristics
- **Motivation**: Financial gain, often with minimal ethical constraints
- **Capabilities**: Increasingly sophisticated, but often less resourceful than state actors
- **Methods**: Opportunistic attacks, social engineering, automation

#### Criminal Infrastructure

**Criminal Ecosystem**:
- **Botnet Herders**: Control networks of compromised devices
- **Malware Developers**: Create malicious software
- **Spam Senders**: Distribute phishing emails and malware
- **Cashout Gangs**: Convert stolen data into cash

#### Evolution of Cybercrime

| Era | Characteristics | Key Developments |
|-----|----------------|------------------|
| **1980s-1990s** | Early fraud, limited scale | Card fraud, early phishing |
| **2000s** | Cottage industry | Individuals or small groups collecting credit card numbers |
| **2003-2005** | Industrialization | Underground markets emerged enabling specialization |
| **2010s-Present** | Professionalization | Criminal infrastructure with specialized roles |

#### Key Attack Types

##### 2.3.1 Botnets
- **Definition**: Networks of compromised computers controlled by attackers
- **Evolution**:
  - **1996**: First botnets (e.g., attack on ISP Panix)
  - **2000**: Earthlink spammers sent over a million phishing emails
  - **2007**: Storm botnet (8% of all Windows malware)
  - **2009**: Conficker botnet (10 million machines)
  - **2016**: Mirai botnet (infected IoT devices, took down Twitter)

**Mirai Botnet**:
- Targeted IoT devices with default passwords
- First major attack: DynDNS (October 2016)
- Took down Twitter for six hours on US eastern seaboard
- Over 1,000 variants since 2016

##### 2.3.2 Malware Development
- **Specialists**:
  - Vulnerability exploit developers
  - Remote access Trojan (RAT) developers
  - Command-and-control communication specialists
  - Bank fraud payload developers

**Key Insight**: 
> "Within each specialist market segment there are typically a handful of operators, so that when we arrest one of them it makes a difference for a while."

##### 2.3.3 Ransomware
- **Evolution**:
  - **2016-2017**: 42% demanded prepaid vouchers (Amazon gift cards)
  - **2017-Present**: Ransomware-as-a-service platforms
  - **2019-2020**: Professional gangs targeting public-sector bodies (hospitals, local governments)

**Ransomware Statistics**:
- 42% of ransomware demanded prepaid vouchers (2016-2017)
- 14% demanded wire transfers
- 12% demanded cryptocurrency
- Low-end ransomware often doesn't actually encrypt files (scareware)

##### 2.3.4 Attacks on Banking and Payment Systems
- **Card Fraud**:
  - Traditional: Lost/stolen cards, forgery
  - Modern: Hacking retailers, card numbers harvested
  - Cost: Card fraud doubled over a decade (2011-2019), but loss percentage of transaction value slightly decreased

- **Business Email Compromise (BEC)**:
  - Compromise business email accounts
  - Impersonate CEO to order payments
  - Social engineering attacks (e.g., "bank account number changed")

**Key Insight**: 
> "Most targeted attacks on company payment systems can in theory be prevented by the control procedures that most large firms already have, and so the typical target is a badly-run large firm, or a medium-sized firm with enough money to be worth stealing but not enough control to lock everything down."

---

### 2.4 Geeks: Security Researchers

#### Key Characteristics
- **Motivation**: Curiosity, professional acclaim, ethical concerns
- **Capabilities**: Technical expertise, research skills
- **Methods**: Vulnerability discovery, responsible disclosure

#### Responsible Disclosure
- **Definition**: Process where researchers disclose vulnerabilities to vendors before public disclosure
- **Evolution**:
  - Early 2000s: Industry evolved practices of responsible disclosure
  - Many firms now operate bug-bounty programs
  - Researchers can earn serious money selling vulnerabilities

**Bug Bounty Programs**:
- Offer rewards for vulnerability reports
- Can earn over $1 million for successful vulnerability reports
- Some firms buy vulnerabilities to weaponize them

#### Ethical Considerations
- **Whistleblower Protection**: 
  > "Many security engineers think the right countermeasure to leaks is technical, such as data loss prevention systems, but robust mechanisms for staff to report wrongdoing are usually more important."

- **Case Study: Volkswagen Emissions Scandal**:
  - Diesel engines programmed to run cleanly during emissions tests
  - CEO fired and indicted in the USA
  - VW set aside â‚¬25 billion for fines and compensation
  - Demonstrated corporate attacks on regulatory systems

---

### 2.5 The Swamp: Abuse Against People

#### Key Characteristics
- **Motivation**: Malice, control, political influence
- **Capabilities**: Varies widely from individuals to state actors
- **Methods**: Harassment, doxxing, intimidation

#### Types of Abuse

##### 2.5.1 Hacktivism and Hate Campaigns
- **Definition**: Using technology to promote political or social causes, often through disruptive means
- **Evolution**:
  - 1990s: Email mobilization against surveillance bills
  - 2000s: Online activism (Indymedia, Avaaz)
  - 2011: Arab Spring (Wael Ghonim)
  - 2014: Gamergate (misogynistic harassment)

**Gamergate (2014)**:
- Started with abusive comments about a female game developer
- Cascaded into misogynistic criticism of women in gaming industry
- Coordinated on anonymous message boards (4chan)
- Contributed to development of alt-right movement

**Key Insight**: 
> "Online shaming has become popular as a means of protest. It can be quite spontaneous, with a flash mob of vigilantes forming when an incident goes viral."

##### 2.5.2 Child Sex Abuse Material (CSA)
- **Legal Context**: Regulated by Budapest Convention (2001)
- **Key Problems**:
  - Forensic failures (e.g., Operation Ore in UK)
  - Takedown inefficiencies (days/weeks)
  - Law-norm gap (teens sending intimate photos can be criminalized)

**Operation Ore (UK)**:
- Thousands of men arrested based on credit card numbers
- Half turned out to be victims of credit card fraud
- Hundreds of innocent men had lives ruined
- Highlighted forensic failures in handling CSA material

##### 2.5.3 School and Workplace Bullying
- **Statistics**:
  - UK survey: 25% of children constantly bullied (13% verbal, 5% cyber, 3% physical)
  - 50% bullied sometimes (24% verbal, 8% cyber, 9% physical)
  - French survey: 2 million cases of threatening behavior (7% on social media, 9% by phone)

**Key Insight**: 
> "The effect of social media use on adolescent well-being are nuanced, small at best, and contingent on analytic methods."

##### 2.5.4 Intimate Partner Abuse
- **Statistics**: 27% of women and 11% of men experience intimate partner abuse
- **Technology Impact**: 
  - Abusers have deep contextual knowledge (can answer password recovery questions)
  - Three phases: physical control, high-risk escape, life apart
  - Average 7 escape attempts to reach "life apart"

**Key Insight**: 
> "All the usual advice is the wrong way round: your opponent knows not just your passwords but has such deep contextual knowledge that he can answer all your password recovery questions."

**Stalkerware**:
- Apps designed to monitor partners, ex-partners, children
- Poor information security practices
- Marketed explicitly to abusive men
- Over half of abusers tracked women using stalkerware (in Europe/Canada)

---

### 2.6 Summary

#### Four Main Categories of Adversaries

| Category | Primary Motivation | Key Characteristics | Examples |
|----------|-------------------|---------------------|----------|
| **Spies** | National security, economic advantage | Advanced technical resources, legal authority | Prism, Tempora, Stuxnet |
| **Crooks** | Financial gain | Increasing sophistication, criminal infrastructure | Ransomware, BEC, Mirai botnet |
| **Geeks** | Curiosity, professional acclaim | Technical expertise, vulnerability discovery | Responsible disclosure, bug bounties |
| **The Swamp** | Malice, control | Varies widely from individuals to states | Gamergate, CSA, intimate partner abuse |

#### Critical Security Principles

> "It's not enough to rely on patching and antivirus. You need to watch your network and keep good enough logs that when an infected machine is spotted you can tell whether it's a kid building a botnet or a targeted attacker."

> "You need to think systematically about your essential controls: backup to recover from ransomware, payment procedures to block business email compromise, and so on."

#### Key Takeaways

1. **Threat Modeling is Essential**: Understand who might attack you before designing security systems
2. **Adversary Types Matter**: Different adversaries require different defensive strategies
3. **Criminal Infrastructure is Professionalized**: Cybercrime has evolved from cottage industry to industrialized ecosystem
4. **The Lines Blur**: State actors, criminals, and hacktivists often operate in overlapping spaces
5. **Abuse Scales Differently**: Understanding how abuse scales is critical for designing secure systems

---

### Review Questions

1. What are the four main categories of adversaries in cybersecurity according to the chapter?
2. How did cybercrime evolve from the 1980s to the present?
3. What is the difference between "responsible disclosure" and "bug bounty" programs?
4. Why is attribution in cybercrime often more difficult than it seems?
5. What are the three phases of intimate partner abuse in the context of technology?
6. How does the criminal infrastructure for cybercrime compare to traditional business models?
7. What are the key characteristics of the Mirai botnet and its impact?
8. Why is the Budapest Convention on child sex abuse material problematic?

---

### Key Terms and Definitions

| Term | Definition |
|------|------------|
| **Threat Modeling** | The process of identifying potential adversaries and understanding their capabilities, motivations, and methods before designing security systems |
| **Botnet** | A network of compromised computers controlled by an attacker, often used for spam, DDoS attacks, or malware distribution |
| **Ransomware** | Malware that encrypts a victim's files and demands payment for decryption |
| **Responsible Disclosure** | Process where security researchers disclose vulnerabilities to vendors before public disclosure |
| **BEC (Business Email Compromise)** | A type of cybercrime where attackers compromise business email accounts to initiate fraudulent wire transfers |
| **CSA (Child Sex Abuse Material)** | Images or videos depicting child sexual abuse, regulated by the Budapest Convention |
| **Stalkerware** | Apps designed to monitor partners, ex-partners, children, or employees, often used in abusive relationships |
| **Ransomware-as-a-Service** | A business model where ransomware operators provide the malware and infrastructure to affiliates who carry out attacks |

---

### Summary Box: The Four Categories of Adversaries

| Category | Primary Motivation | Key Characteristics | Defense Approach |
|----------|-------------------|---------------------|------------------|
| **Spies** | National security, economic advantage | Advanced technical resources, legal authority, long-term patience | Network monitoring, encryption, supply chain security |
| **Crooks** | Financial gain | Increasing sophistication, criminal infrastructure | Patching, antivirus, employee training, fraud detection systems |
| **Geeks** | Curiosity, professional acclaim | Technical expertise, vulnerability discovery | Bug bounty programs, responsible disclosure policies |
| **The Swamp** | Malice, control | Varies widely from individuals to states | User education, reporting mechanisms, content moderation |

> "The systems you build or operate can be attacked by a wide range of opponents. It's important to work out who might attack you and how, and it's also important to be able to figure out how you were attacked and by whom."

---

### Further Reading

- **Snowden Revelations**: Glenn Greenwald's *No Place to Hide* [817]
- **Russian Strategy**: 2018 report to the US Senate's Committee on Foreign Relations [387]
- **History of Propaganda**: Tim Wu's *The Attention Merchants* [2052]
- **Cybercrime Surveys**: "Measuring the Cost of Cybercrime" [91] and "Measuring the Changing Cost of Cybercrime" [92]
- **Gamergate**: ZoÃ« Quinn's *CrashOverride* [1570]
- **Marcus Hutchins**: Story of the malware expert who stopped Wannacry [812]


---

# Chapter 3: Passwords - Comprehensive Study Notes

<think>
I need to create comprehensive study notes from the textbook chapter on "Passwords" from Chapter 3 of Anderson's book. I'll organize this into a well-structured markdown document with proper headings, key concepts highlighted, and all important information extracted.

Let me analyze the chapter content first to understand the structure and key topics:

The chapter covers:
1. Password management as a context where usability, psychology, and security meet
2. Password recovery mechanisms
3. Password choice and psychological aspects
4. Difficulties with reliable password entry
5. Difficulties with remembering passwords
6. Design errors in password systems
7. Operational failures
8. Social-engineering attacks
9. System issues related to passwords
10. Attacks on password entry
11. Attacks on password storage
12. Password managers
13. The future of passwords

I'll structure my notes to follow this flow, creating clear hierarchical sections with appropriate headers.

Let me start by creating the chapter title and learning objectives (though the chapter doesn't explicitly state learning objectives, I'll infer them from the content).

Now, I'll extract key information from each section, highlighting important concepts, definitions, examples, and theories.

I'll need to:
- Create proper markdown headers
- Use bullet points for lists
- Bold important terms
- Include key examples and case studies
- Note formulas and technical specifications
- Create summary boxes for complex concepts
- Add a comprehensive summary at the end
- Include review questions if mentioned (though I don't see any explicitly in the text)

Let me begin creating the notes.
</think>


### Chapter Overview
This chapter examines passwords as a critical intersection of usability, psychology, and security. It explores the psychological challenges of password management, common security failures, and the evolution of authentication systems. Passwords remain a foundational but problematic element of information security despite numerous attempts to replace them.

---

### Key Concepts & Definitions

| Term | Definition |
|------|------------|
| **Password** | A secret string of characters used for authentication |
| **Password entropy** | Measure of unpredictability in a password (higher entropy = more secure) |
| **One-way encryption** | Cryptographic technique where password is transformed into a fixed-length hash that cannot be reversed |
| **Salt** | Random value added to password before hashing to prevent rainbow table attacks |
| **Phishing** | Deceptive attempt to obtain sensitive information by masquerading as a trustworthy entity |
| **Social engineering** | Manipulation of people into divulging confidential information |
| **Two-factor authentication (2FA)** | Authentication requiring two different factors (something you know + something you have) |
| **Credential stuffing** | Attack where stolen credentials from one breach are used to access other systems |

---

### 3.4 Passwords: The Core Problem

#### Why Passwords Are Problematic
- **Human memory limitations**: People can't remember infrequently-used or frequently-changed items
- **Recall vs. recognition**: Recall is harder than recognition
- **Non-meaningful words**: More difficult to remember than meaningful ones
- **"Worse authentication mechanism"**: As Angela Sasse states, passwords are among the worst authentication mechanisms given human memory constraints

> "It's hard to think of a worse authentication mechanism than passwords, given what we know about human memory."

#### The Marketing Ecosystem
- Websites force password creation to maximize page views and registered user base
- Example: News sites require registration to comment, with multiple ad pages before comment submission
- Users often enter random garbage or skip registration entirely

---

### 3.4.1 Password Recovery

#### Evolution of Password Recovery
1. **Security questions** (1990s-2010s): 
   - Questions like "mother's maiden name," "favorite team," "first school"
   - **Major flaws**: 
     - Near-public information (easy to guess)
     - Same questions used across sites
     - Celebrities' information often public (e.g., Sarah Palin's Yahoo hack in 2008)
     - 37% of people provided wrong answers; 16% answers were public

2. **Email recovery** (Current standard):
   - Email to registered address
   - **Flaw**: Compromising email account compromises all dependent accounts
   - **Critical for important accounts**: Banking/email require second factor

3. **Second factor authentication**:
   - SMS codes (96% stop bulk password guessing, 76% stop targeted attacks)
   - **Flaws**: 
     - SIM swap attacks (2007-2020)
     - SS7 protocol exploitation
   - **Better solution**: Authentication apps (99% stop bulk phishing, 90% stop targeted attacks)

> "Google research shows that SMS stops all bulk password guessing by bots, 96% of bulk phishing and 76% of targeted attacks."

#### Security Trade-offs
- **Email recovery**: Adequate for low-consequence sites, but inadequate for banking/email
- **Second factor**: Essential for high-value accounts
- **Recovery mechanism strength**: "Only as strong as the weakest fallback mechanism"

---

### 3.4.2 Password Choice: Three Key Concerns

1. **Correct entry probability**: Will the user enter the password correctly with high probability?
2. **Memory retention**: Will the user remember the password, or will they write it down/choose weak one?
3. **Disclosure risk**: Will the user disclose the password to third parties (accidentally, on purpose, or via deception)?

> "Standard password advice has been summed up as: 'Choose a password you can't remember, and don't write it down'."

---

### 3.4.3 Difficulties with Reliable Password Entry

#### Key Issues
- **Length/complexity**: Long/complex passwords cause entry errors
- **Mobile transition**: 2010s shift from laptops to smartphones made complex password rules "fiddly and annoying"
- **Workarounds**: 
  - Longer but simpler secrets (passphrases)
  - STS prepayment meters: Printed 20-digit numbers in two rows (3 groups of 4 + 2) to reduce errors
  - Nuclear weapons: 12-digit codes (max reliable under stress)

> "The move from laptops to smartphones during the 2010s has made password rules such as 'at least one lower-case letter, upper-case letter, number and special character' really fiddly and annoying."

---

### 3.4.4 Difficulties with Remembering Passwords

#### Five Main Headings

##### 3.4.4.1 NaÃ¯ve Choice
- **Common patterns**: 
  - Spouses' names (e.g., "wendy!!!" for Eric Schmidt)
  - Single letters
  - Empty string (carriage return)
  - Dictionary words (7.4% of passwords)
  - Common names (4%)
  - Account name combinations (2.7%)
- **Studies**:
  - 1980s Unix systems: 21-25% of passwords guessable
  - 1990s: 25,000 Unix passwords showed 21-25% guessable
  - 2012: Joe Bonneau analyzed tens of millions of passwords

> "The largest academic study of password choice of which I am aware is by Joe Bonneau, who in 2012 analyzed tens of millions of passwords in leaked password files."

##### 3.4.4.2 User Abilities and Training
- **Training effectiveness**:
  - **Control group**: Standard advice (6+ chars, 1 non-letter) â†’ 30% guessable
  - **Green group**: Passphrase â†’ 10% guessable
  - **Yellow group**: Random 8-character â†’ 10% guessable
- **Key finding**: Passphrases offer best of both worlds (easy to remember, hard to guess)
- **Compliance issue**: ~1/3 of users don't follow instructions

> "For users who follow instructions, passwords based on mnemonic phrases offer the best of both worlds. They are as easy to remember as naively selected passwords, and as hard to guess as random passwords."

##### 3.4.4.3 Design Errors
- **Classic error**: "Mother's maiden name" as security question
- **Data sharing**: Companies share data, making recovery questions vulnerable
- **Password reuse**: Average user has 6.5 passwords shared across 3.9 sites
- **Forced password changes**: 
  - 1980s: Led to patterns like "julia03" for March, "julia04" for April
  - NIST 2003 recommendation (later recanted in 2017)
  - Current recommendation: Long passphrases only changed on compromise

> "NIST recanted; they now recommend long passphrases that are only changed on compromise."

##### 3.4.4.4 Operational Failures
- **Default passwords**: Systems with unchangeable default passwords (e.g., IoT devices)
- **Passwords in plain sight**: Sticky notes, electronic equivalents
  - *Case study*: R v Gold and Schifreen (1980s) - hackers used maintenance password from a note on a terminal
- **Unnecessary password requests**: Marketing reasons (e.g., news sites requiring registration)
- **Poor password management**: Systems not encrypting passwords

> "The most pervasive operational error is failing to reset default passwords. This has been a chronic problem since the early dial access systems in the 1980s."

##### 3.4.4.5 Social-Engineering Attacks
- **Bank marketing vs. security**: Banks send emails with clickable links, training customers to click on phishing links
- **Phishing examples**:
  - Bank of America email to UK customers directed to `mynewcard.com` (wrong certificate)
  - Citibank asking customers to provide PIN via email
  - Halifax sending spam to mother of student who contacted security department

> "Banks also call us on our mobiles now and expect us to give out security information to a whole train carriage of strangers, rather than letting us text a response."

##### 3.4.4.6 Customer Education
- **Phishing countermeasures**:
  - "Check the English" â†’ phishers used bank's own emails with URL changes
  - "Look for the lock symbol" â†’ phishers used SSL/graphics
  - "Check where link would go" â†’ phishers used non-printing characters in URLs
- **Key insight**: "Blame and train" is not the way to deal with unusable systems

> "The countermeasures become so complex and counterintuitive that they confuse more and more users â€“ exactly what the phishermen need."

##### 3.4.4.7 Phishing Warnings
- **Effective warnings**: Specific and concrete (e.g., "The site you are about to visit has been confirmed to contain software that poses a significant risk to you...")
- **Ineffective warnings**: Vague (e.g., "Warning - visiting this web site may harm your computer!")
- **Improvement**: Specific warnings increase compliance from ~35% to ~50%

> "People paid most attention when the warnings were not vague and general but specific and concrete."

---

### 3.4.5 System Issues

#### Password Guessing Attack Types

| Attack Type | Description | Example |
|-------------|-------------|---------|
| Targeted attack on one account | Intruder guesses specific user's password | Office rival's logon password |
| Penetrate any account of specific target | Hacker tries to hack any account owned by target | Bank account for money laundering |
| Penetrate any account on target system | Hacker tries to get logon as any user of system | Phisher hacking bank accounts |
| Penetrate any account on any system | Hacker wants any account in given domain | Spam from compromised email accounts |
| Use breach to penetrate related system | Hacker uses beachhead to move to higher-value targets | Spear-phishing sysadmin to chain into network |
| Service-denial attack | Attacker blocks legitimate users from system | Blocking specific account or system-wide |

---

### 3.4.6 Can You Deny Service?

#### Three Approaches to Password Guessing Detection

| Method | Description | Pros | Cons |
|--------|-------------|------|------|
| **Lockout** | Freeze account after failed attempts | Simple | Vulnerable to denial-of-service attacks |
| **Throttling** | Limit rate of attempts | More secure than lockout | May not prevent all attacks |
| **Protective monitoring** | Monitor for suspicious activity | Flexible | Requires sophisticated monitoring |

> "Popular, growing, competent sites tend to be more secure, as do payment sites, while content sites do worst."

---

### 3.4.7 Protecting Oneself for Others?

#### Key Considerations
- **Personal aspect**: Passwords chosen by victims of intimate partner abuse are often easy for partners to guess
- **System aspect**: 
  - Mutual authentication between subsystems
  - Default passwords (e.g., "changeit" for Java trusted keystore)
  - Passwords shared in scripts/plaintext files
  - "Spear-phish a sysadmin and then chain your way in" (Ed Snowden)

> "Within a single big service firm you can lock stuff down by having named crypto keys and seeing to it that each name generates a call to an underlying hardware security module."

---

### 3.4.8 Attacks on Password Entry

#### 3.4.8.1 Interface Design
- **Problem**: Vertical keyboards at head height (easy for pickpockets to watch PIN entry)
- **Data**: 20% of UK users never shield their PIN

#### 3.4.8.2 Trusted Path and Bogus Terminals
- **False terminal attack**: Malicious program mimicking logon screen
- **Solution**: Secure attention sequence (e.g., Ctrl-Alt-Del in Windows)
- **ATM skimmers**: Devices copying card details + recording PIN

#### 3.4.8.3 Technical Defeats of Password Retry Counters
- **Timing attacks**: 
  - PDP-10 TENEX: Checked passwords one character at a time
  - Attackers could guess characters sequentially based on response time
  - iPhone PIN retry counter: Could try all 10,000 PINs instead of 10

> "The iPhone keeps sensitive data encrypted in flash memory, and built an adapter that enabled him to save the encrypted memory contents and restore them to their original condition after several PIN attempts. This enabled him to try all 10,000 possible PINs rather than the ten PINs limit that Apple tried to impose."

---

### 3.4.9 Attacks on Password Storage

#### 3.4.9.1 One-Way Encryption
- **Correct implementation**:
  1. Generate random salt
  2. Combine password with salt
  3. Use slow, cryptographically strong one-way function
  4. Store both salt and hash
- **Common mistake**: Not using salt or using weak hashing

#### 3.4.9.2 Password Cracking
- **Credential stuffing**: Using cracked passwords from one breach on other systems
- **Countermeasures**: 
  - Honeypot systems
  - Honey-pot accounts
  - Password canaries (bogus encrypted passwords)

> "Credential stuffing remains a live problem. So password cracking is still worth some attention."

#### 3.4.9.3 Remote Password Checking
- **Kerberos**: Server sends key encrypted under user's password
- **TLS**: Encrypts traffic from browser to server
- **SAE (Simultaneous Authentication of Equals)**: New protocol for WPA3 (2018) for secure sessions with guessable passwords
- **OAuth**: Allows access delegation (e.g., "Log in with Google"), but vulnerable to phishing

> "OAuth is now used by main service providers such as Google, Microsoft and Facebook to let you log on to media and other sites."

---

### 3.4.10 Absolute Limits

#### Password Guessing Probability Formula
$$P = \frac{LR}{S}$$
Where:
- $P$ = Probability password can be guessed in its lifetime
- $L$ = Maximum password lifetime
- $R$ = Login attempt rate
- $S$ = Size of password space

> "If passwords are not case sensitive, the guess probability is cut drastically, to only one in 214.52.102 or about 2^-29."

---

### 3.4.11 Using a Password Manager

#### Benefits
- Browser-based: 
  - Only enters password on correct URL
  - Master password encrypts individual site passwords
  - Syncs between devices
- Third-party: 
  - Chooses long random passwords
  - Identifies passwords shared across sites
  - Better backup/recovery options

#### Drawbacks
- Forgetting master password
- All passwords compromised at once if malware steals them
- Banks disabling password storage (making users use weaker passwords)

> "Stopping people using password managers or the browser's own storage will probably make most of them use weaker passwords."

---

### 3.4.12 Will We Ever Get Rid of Passwords?

#### Authentication Alternatives
1. **Physical tokens** (e.g., CAP reader for bank cards)
2. **Biometrics** (fingerprint readers on mobile phones)
3. **Single sign-on** (e.g., Google/Facebook login)
4. **Trust on first use** (e.g., "resurrecting duckling" concept)

#### Current Reality
- **Monzo**: Exclusive app authentication (fingerprint, pattern, PIN, or password)
- **WhatsApp**: Popular app using SMS for authentication
- **Banks**: Still rely on email + password recovery questions

> "Passwords remain the (shaky) foundation on which much of information security is built."

---

### Comprehensive Summary

#### Key Takeaways
1. **Psychological challenges**: Passwords conflict with human memory capabilities
2. **Security flaws**: 
   - Weak password choices (dictionary words, common patterns)
   - Poor recovery mechanisms (security questions)
   - Social engineering vulnerabilities
3. **Technical issues**: 
   - Insecure storage (lack of salt, weak hashing)
   - Timing attacks on password entry
   - Credential stuffing
4. **Solutions**:
   - Passphrases (3+ random words) over complex passwords
   - Second factor authentication (app-based > SMS)
   - Password managers (with master password)
   - Avoiding forced password changes
5. **Future**: Passwords will persist as a foundation, but will be supplemented by biometrics and other authentication methods

> "Passwords are annoying, so many people have discussed getting rid of them, and the move from laptops to phones gives us a chance. The proliferation of IoT devices that don't have keyboards will force us to do without them for some purposes."

---

### Review Questions

1. **Why are passwords considered one of the worst authentication mechanisms?**
   - They conflict with human memory capabilities (people can't remember infrequently-used or frequently-changed items)
   - Recall is harder than recognition
   - Non-meaningful words are more difficult to remember

2. **What are the three main concerns with password choice?**
   - Will the user enter the password correctly with high probability?
   - Will the user remember the password, or will they write it down/choose a weak one?
   - Will the user disclose the password to a third party?

3. **What are the key flaws with security questions for password recovery?**
   - Near-public information (easy to guess)
   - Same questions used across sites
   - Celebrities' information often public
   - 37% of people provided wrong answers; 16% answers were public

4. **What is the most effective password recovery method for high-value accounts?**
   - Second factor authentication (app-based > SMS)
   - SMS stops 96% of bulk password guessing and 76% of targeted attacks
   - App-based authentication stops 99% of bulk phishing and 90% of targeted attacks

5. **What is the current NIST recommendation for password management?**
   - Long passphrases that are only changed on compromise
   - Avoid forced regular password changes

6. **What are the three main approaches to dealing with password guessing?**
   - Lockout (freeze account after failed attempts)
   - Throttling (limit rate of attempts)
   - Protective monitoring (monitor for suspicious activity)

7. **What is the formula for calculating the probability of a successful password guessing attack?**
   - $P = \frac{LR}{S}$ where:
     - $P$ = Probability password can be guessed in its lifetime
     - $L$ = Maximum password lifetime
     - $R$ = Login attempt rate
     - $S$ = Size of password space

---

### Key Case Studies

| Case Study | Year | Lesson |
|------------|------|--------|
| Sarah Palin Yahoo Hack | 2008 | Security questions (date of birth, first school) were public information |
| R v Gold and Schifreen | 1980s | Hackers used maintenance password from a note on a terminal |
| Miraibotnet | 2010s | Exploited IoT devices with default passwords |
| iPhone PIN Attack | 2010s | Researchers could try all 10,000 PINs instead of 10 due to flawed retry counter |
| Citibank Email Phishing | 2005 | Bank sent email asking customers to provide PIN via email |

---

### Critical Insights

> "The main cause of attempted password abuse is when one firm gets hacked, disclosing millions of email addresses and passwords, which the bad guys try out elsewhere; big firms spot this quickly while small ones don't."

> "Password recovery is often the hardest aspect of authentication. For people you don't know, such as online customers, it's harder to recover accounts without human intervention in the vast majority of cases."

> "The most pervasive operational error is failing to reset default passwords. This has been a chronic problem since the early dial access systems in the 1980s."

> "Banks also call us on our mobiles now and expect us to give out security information to a whole train carriage of strangers, rather than letting us text a response."

> "The countermeasures become so complex and counterintuitive that they confuse more and more users â€“ exactly what the phishermen need."


---

# Week 1: The Key To Capability Alignment

<think>
Okay, the user wants me to create comprehensive academic notes from a lecture transcript about cyber conflict and AI alignment. This is for Ross J. Anderson's CyCon2023 keynote on "The Key To Capability Alignment."

First, I need to understand the core themes. The lecture focuses on how traditional cyber capabilities have flaws due to misaligned incentives, and how AI introduces new alignment challenges. Anderson uses historical examples like Stuxnet and PRISM to show past failures, then presents data-driven debunking of myths about civilian hackers and online safety bills.

Hmm, the transcript has several key sections I should organize: 
- Traditional cyber capability flaws (with examples)
- Data-driven debunking (civilian hackers, Kiwi Farms case)
- Cold War 1 vs. modern failures
- AI alignment problems (Trojan Source vulnerability, LLM risks)
- China vs. West approaches to AI ethics

I notice the user emphasized "no slides available" so I must strictly use only the transcript. The challenge is structuring the dense content logically. The lecture flows from historical critique â†’ data examples â†’ systemic failures â†’ AI-specific risks â†’ future implications.

For the title, I'll use the exact lecture title but add "Comprehensive Notes" for academic clarity. The overview should capture the central thesis: "Alignment is the key to effective cyber capability, and current misalignment causes systemic failures."

*checks transcript again* 
Ah, Anderson's core argument is that "large complex systems fail because incentives are wrong" - that's the anchor point. I'll make that the first key concept. The Stuxnet example perfectly illustrates this with governments undermining firms.

For the debunking section, I need to present both cases clearly:
1. Civilian hackers = propaganda (280k defacements but no military impact)
2. Kiwi Farms takedown failed because they didn't arrest the leader (unlike Silk Road)

*noting important phrases* 
Must include his vivid metaphors: "writing Putin sucks on a bus shelter" for propaganda value, and "merry tricks with bi-directional control characters" for the Trojan Source vulnerability.

The Cold War 1.0 vs. modern section is crucial. I'll contrast:
- 1950s: competing suppliers, fair practices, academic funding
- Now: monopolies, crypto undermining, talent drain

*checking for key terms* 
"Alignment problem" appears 5 times - this is the thesis. Need to define it early: "ensuring AI systems act in accordance with human values and security goals."

For the China vs. West comparison, I'll highlight:
- China: "must promote communist rule" (simple alignment)
- West: "morally diverse" with hypocrisy (complex alignment)

*planning structure* 
I'll avoid chronological order and group by theme instead. The transcript jumps between topics, so I'll cluster:
- Foundational concepts (incentives, alignment definition)
- Historical failures (with examples)
- Data-driven evidence (two case studies)
- Systemic modern failures (Cold War 2.0)
- AI-specific vulnerabilities
- Future implications (China comparison)

*verifying completeness* 
The Q&A section adds nuance about "steelyard approach" to terrorism - must include that as a key takeaway. Also the "raising robots like raising kids" metaphor is too good to omit.

*formatting check* 
Will use # for main sections, ## for subsections. Bullet points for examples, bold for key terms like "Trojan Source vulnerability." No markdown tables since it's a transcript.

*double-checking instructions* 
User said "no slides" so I won't invent any. Every point must be in the transcript. For instance, when he says "Oracle refused to patch," I'll cite that directly.

*key summary point* 
The conclusion must stress his final line: "When raising robots it's a bit like raising kids: we need to say what we mean and we need to mean what we say." That's the thesis in a nutshell.

*avoiding pitfalls* 
Don't confuse "alignment" (AI ethics) with "capability alignment" (cyber strategy). The lecture uses both but they're distinct. I'll clarify in the definitions section.

*adding academic rigor* 
Will reference his papers ("Getting Bored of Cyber War," "Talking Trojan") as mentioned, since they're part of the lecture content.

Okay, structuring now: 
Title â†’ Overview â†’ Core Concepts â†’ Historical Flaws â†’ Data Evidence â†’ Systemic Failures â†’ AI Alignment Deep Dive â†’ China vs West â†’ Conclusion. Ending with "Key Takeaways" as requested.

*last check* 
The transcript mentions "5 eyes" alliance - must explain it's intelligence-sharing (US, UK, Canada, Australia, NZ) when first used. But since it's a lecture, I'll assume audience knows. No need to define in notes.

Time to write. Keeping every point traceable to the transcript.
</think>

**Date:** October 26, 2023  
**Source:** Ross J. Andersonâ€™s CyCon2023 Keynote Speech  

---

### Overview  
This lecture examines the critical concept of **"alignment"** in cyber conflict, arguing that historical misalignment of incentives between governments, industry, and citizens has caused systemic security failures. Anderson demonstrates how data-driven analysis debunks myths about cyber warfare (e.g., civilian hackersâ€™ military impact), exposes modern strategic errors (e.g., crypto undermining, talent drain), and identifies AIâ€™s emerging alignment challenges. The core thesis: *Effective cyber capability requires principled alignment of incentives, not exploitative relationships*.  

---

### Core Concepts & Definitions  
#### **Alignment**  
- **Definition**: Ensuring systems (human or AI) act in accordance with shared values and security goals.  
- **Historical Failure**: "Large complex systems tend to fail because the incentives are wrong."  
  - *Key Principle*: "If Alice is guarding a system and Bob is paying the cost of failure, you can expect trouble."  
- **AI-Specific Challenge**: As AI approaches AGI, aligning its behavior with human values becomes existential (e.g., preventing misuse for "genocide" via language manipulation).  

#### **Capability Misalignment**  
- **Traditional Model**: Exploitative relationships between governments, firms, and citizens.  
- **Consequence**: "A hell of a lot of bad security" (e.g., unprotected industrial control systems, insecure payment networks).  

---

### Historical Cyber Capability: Flaws & Examples  
#### **Traditional Exploitative Relationships**  
| **Example**               | **Mechanism**                                                                 | **Flaw**                                  |  
|---------------------------|-----------------------------------------------------------------------------|------------------------------------------|  
| **Stuxnet**               | Gov A (US) attacks Gov C (Iran) via Firm B (Siemens controllers)            | Weaponization on test ranges; no industry collaboration |  
| **Export Controls**       | Gov A restricts Firm Bâ€™s exports to Gov C (e.g., ASML stock price impact)   | Economic coercion over security            |  
| **Covert Undermining**    | NSA uses PRISM to read emails (e.g., Assadâ€™s wife) for regime insights       | Surveillance as intelligence tool          |  
| **Recruitment of Hackers**| Gov A recruits Group D to attack Gov C                                      | Unregulated "cyber mercenaries"            |  

#### **Root Cause**  
- **Incentive Misalignment**: "Alice guards the system, Bob pays for failure" â†’ Systemic neglect of security.  
- **Data Gap**: Platforms like Twitter "going dark" (API access loss) hinders academic research on extremism.  

---

### Data-Driven Debunking of Cyber Conflict Myths  
#### **Myth 1: Civilian Hackers Have Military Impact**  
- **Claim**: "Whole of society effort" with volunteers attacking enemy sites (e.g., Ukraine-Russia conflict).  
- **Data**: 280,000+ web defacements, 1M+ reflected DDoS attacks, but **no military consequence**.  
- **Conclusion**: "Best described as propaganda" (e.g., "writing Putin sucks on a bus shelter").  
- **Source**: *Getting Bored of Cyber War* (Anderson et al.).  

#### **Myth 2: Online Safety Bills Can Takedown Hate Groups**  
- **Case Study**: Kiwi Farms (hate site for doxing/swatting) takedown (2022).  
  - **Campaign**: Activists pressured Cloudflare (ex-free speech absolutist) to cut service.  
  - **Failure**: Site returned within weeks; *no arrests* of leader (Jason Moon).  
  - **Contrast**: FBIâ€™s Silk Road takedown succeeded via *arrest + site shutdown*.  
- **Conclusion**: "Didnâ€™t work long-term" without targeting leadership.  
- **Source**: *No Easy Way Out* (Anderson et al.).  

> **Key Insight**: "Achieving reasonable results requires the right coordination between government and private sector."  

---

### Systemic Failures: Cold War 1.0 vs. Modern Era  
#### **Cold War 1.0 (1950sâ€“1980s) â€“ Virtues**  
| **Principle**               | **Example**                                                                 |  
|-----------------------------|---------------------------------------------------------------------------|  
| **Purposeful Industrial Relationships** | Radar, antibiotics, computers (e.g., Sir Maurice Wilkesâ€™ grant-funded computer) |  
| **Competing Suppliers**     | Dozens of computer firms â†’ resilience, innovation                          |  
| **Fair Practices**          | Anti-gouging in military contracts                                        |  
| **Academic Funding**        | "Results over process" (no bureaucracy)                                   |  
| **Compensation for Assets** | Requisitioned ships (e.g., Maersk) â†’ paid compensation â†’ rebuilt resilience |  

#### **Modern Failures (Post-1989)**  
| **Failure**                     | **Consequence**                                                                 |  
|---------------------------------|-------------------------------------------------------------------------------|  
| **Military Supply Monopolies**  | Artillery shell shortages in Ukraine (loss of supply resilience)               |  
| **Undermining Cryptography**    | "Crypto Wars" (1990s: blocking crypto; 2000s: backdoors) â†’ insecure systems |  
| **Online Safety Overreach**     | EUâ€™s CSA Regulation (Estonia opposes); UKâ€™s OSB (focus on "harmful but illegal") |  
| **Talent Drain**                | Engineers prefer "Big Tech" (fun, money, future-making) over GCHQ/defense    |  
| **Government as Minor Customer**| Startups canâ€™t sell to government â†’ large contractors hoard funds             |  
| **Alienation**                  | Microsoft (supports Ukraine) vs. Facebook (alienated from agencies)           |  

---

### AI Alignment: The Critical Challenge  
#### **Core Problem**  
- **Alignment**: Ensuring AI systems act in line with human values (not just "Skynet" scenarios).  
- **Key Risk**: AI systems serving "big companies/governments" with "vast electricity bills" could exploit 1,000+ new vulnerabilities yearly.  
- **Existential Priority**: 300+ luminaries demand "mitigating AI extinction risk" as a global priority (like pandemics/nuclear war).  

#### **Critical Vulnerabilities**  
| **Vulnerability**               | **Mechanism**                                                                 | **Impact**                                                                 |  
|---------------------------------|-----------------------------------------------------------------------------|--------------------------------------------------------------------------|  
| **Trojan Source**               | Bi-directional control characters (e.g., Urdu/Hebrew) "anagram" code/email input | Malicious code hidden in translation (e.g., Google Translate altering payment requests) |  
| **LLM "Bad Character" Vulnerability** | LLMs cannot be "multi-level secure" (e.g., cannot handle secret/unclassified info like humans) | Myanmar used BD characters to hide "genocide" calls from journalists via translation |  
| **Patching Failure**            | Maintainers like Oracle refused to patch (Java = "licensing revenue")       | "Lie" to claim itâ€™s an editor issue, not Java vulnerability               |  

> **Source**: *Talking Trojan* (Anderson et al.).  
> **Reality**: "Most large language model maintainers mostly ignore this."  

#### **Alignment Failure in Practice**  
- **Western Hypocrisy**: NSA claims "Global Network of Partners" but scans messages for "grooming terrorism" (same as Chinaâ€™s surveillance).  
- **Equity Bias**: "Second mission orders [offense] are 1,000x more money than defense."  
- **Consequence**: AI systems "struggle to maintain alignment with our values" due to "perpetual conflict between governments and industry."  

---

### China vs. West: AI Alignment Strategies  
| **Approach**                | **China**                                                                 | **West**                                                                 |  
|-----------------------------|---------------------------------------------------------------------------|--------------------------------------------------------------------------|  
| **Alignment Goal**          | "Must promote communist rule; focus on surveillance"                      | "Large language models and text/speech applications"                      |  
| **Challenge**               | Hard to make LLMs "never say anything rude about Communist Party"         | "Morally diverse" societies â†’ complex alignment (e.g., Enlightenment, democracy) |  
| **Advantage**               | Simpler instructions â†’ "robots at distinct advantage early on"            | "Complicated engine" of values â†’ hard to teach AI (vs. human children)   |  
| **Risk**                    | AI "defects to China" if Western hypocrisy is perceived (e.g., "same as China") | "Hypocrisy" undermines global trust in AI alignment                      |  

---

### Key Takeaways & Future Imperatives  
1. **Alignment is Non-Negotiable**:  
   - Cyber capability fails without aligned incentives ("Alice guards, Bob pays cost").  
   - AI alignment is existential: "We need to say what we mean and mean what we say."  
2. **Data Over Myth**:  
   - Civilian hackers = propaganda (not military force).  
   - Online safety bills fail without targeting leadership (Kiwi Farms case).  
3. **Rediscover Cold War 1.0 Virtues**:  
   - Competing suppliers, fair practices, academic funding, compensation for assets.  
   - *Avoid* monopolies, crypto undermining, and talent drain.  
4. **AI Must Be "Multi-Level Secure"**:  
   - Current LLMs cannot handle secret/unclassified info â†’ high risk of misuse (e.g., genocide concealment).  
5. **West Must Address Hypocrisy**:  
   - "Scanning messages for grooming terrorism" is identical to Chinese surveillance â†’ erodes trust.  
   - Prioritize defense over offense ("second mission" funding imbalance).  
6. **Chinaâ€™s Advantage**:  
   - Simpler moral framework â†’ easier AI alignment â†’ potential "defection" of AI systems.  

> **Final Quote**: *"When raising robots itâ€™s a bit like raising kids: we need to say what we mean and we need to mean what we say."*  

---  
**Key References Cited**:  
- *Getting Bored of Cyber War* (Civilian hackers analysis)  
- *No Easy Way Out* (Kiwi Farms takedown)  
- *Talking Trojan* (Trojan Source vulnerability)  
- 300+ luminariesâ€™ AI extinction risk statement (2023)

---

## ðŸ“ Study Guide Summary

This combined study guide contains all notes for **Week 1 Introduction**, automatically generated from 6 individual files.

### Individual Files Included:

1. `20250808_1.md`
2. `20250808_attack_trees.md`
3. `20250808_textbook_27_safety_critical_systems.md`
4. `20250808_textbook_2_who_is_the_opponent.md`
5. `20250808_textbook_4_passwords.md`
6. `20250808_the_key_to_capability_alignment.md`

### Usage Tips:
- Use the table of contents above to navigate quickly
- Each section is separated by horizontal rules (`---`)
- Individual files are still available for focused study
- This combined file is perfect for comprehensive review

---
*Generated by [LectureQ](https://github.com/yourusername/lectureq) - Your AI-powered study companion* ðŸ¤–
